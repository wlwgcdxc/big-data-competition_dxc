##利用豆瓣书评数据，向用户推荐，用户可能会读的书籍。

####数据集
![](https://github.com/wlwgcdxc/picture/blob/master/ASL0.1.PNG)
每行数据分别是：[用户ID,书ID,用户对书的评价]
##下面分别使用两种方法对用户做推荐。第一种简单介绍传统的处理方式，第二种是使用spark的ALS算法，对用户做推荐
###第一种
#####特征提取
- 提取[读者，读者的读数量]，并按读书量排序
- 提取[书籍，书籍的总读者量]，并按总读者量排序
- 选取读书量比较多的部分读者和被评价量比较多的部分书籍作为核心数据，为之后建立文档型向量做准备（否则，整个矩阵会相当稀疏）
- 对所有读者和图书信息，抽取如下特征，可做其他事情，比如读者阅读量的排名，判断读者是否更挑剔，或者更容易得到满足
    [读者，读者所读的书籍，读者对书的评分，读者总共的读数量，读者对书籍的评价评分，书籍一共被多少个读者评分，书籍的平均评分]

#####生成读者-书籍的文档型向量，即邻近性矩阵

#####使用KNN(K近邻)进行推荐
- 给定用户，给定k值，通过邻近性矩阵找到K个近邻(余弦相似性)
- k个近邻用户所评价的书籍，作为推荐备选
- 使用与用户的邻近性值作为权重，作为推荐书籍的得分，如果有多个近邻推荐同一本书，邻近性累加
- 排除用户本来已经评价过的书籍

###第二种
#####先将数据处理下，这个case主要是想用spark提供的ASL，做推荐。
#####ASL需要用户的产品的ID都为数值型，所以先把不是数值型的数据过滤掉
    import org.apache.spark.mllib.recommendation.ALS
    import org.apache.spark.mllib.recommendation.MatrixFactorizationModel
    import org.apache.spark.mllib.recommendation.Rating
    
    // Load and parse the data
    val data = sc.textFile("/opt/xcdong/data/ALS/douban.dat")
    val ratings_1 = data.map(e => e.split("::")).map(e => (e(0), e(1), e(2)) )
    val ratings_2 = ratings_1.filter{ e => (e._1.toString.matches("[0-9]*") == true)}
    ratings_2.repartition(1).saveAsTextFile("/opt/xcdong/data/ALS/douban_filter.dat")

#####这里观察下，数据集中的用户有多少，商品有多少
    // Load and parse the data
    val data = sc.textFile("/opt/xcdong/data/ALS/douban_filter.dat")
    val ratings = data.map(e => e.substring(1, e.length-1)).map(e => e.split(",")).map{ e => Rating(e(0).toInt, e(1).toInt, e(2).toDouble) }
    val ratings_DF = ratings.toDF
    val user_coun = ratings_DF.select("user").distinct().count
    val product_coun = ratings_DF.select("product").distinct().count
    
        user_coun: Long = 251053 
        product_coun: Long = 76377
可以看到用户有25万，商品有7万多

#####将数据分成训练数据和测试数据
    // Load and parse the data
    val data = sc.textFile("/opt/xcdong/data/ALS/douban_filter.dat")
    val ratings_tmp = data.randomSplit(Array(0.6,0.4),seed = 11L)
    ratings_tmp(0).saveAsTextFile("/opt/xcdong/data/ALS/train/douban_filter")
    ratings_tmp(1).saveAsTextFile("/opt/xcdong/data/ALS/test/douban_filter")

######获取测试数据
    // Load and parse the data
    val data = sc.textFile("/opt/xcdong/data/ALS/train/douban_filter")
    val ratings = data.map(e => e.substring(1, e.length-1)).map(e => e.split(",")).map{ e => Rating(e(0).toInt, e(1).toInt, e(2).toDouble) }

#####使用ALS训练模型
    // Build the recommendation model using ALS
    val rank = 10
    val numIterations = 20
    val model = ALS.train(ratings, rank, numIterations, 0.01)

#####在训练集上评估模型，结果肯定比较好
    // Evaluate the model on rating data
    val usersProducts = ratings.map { case Rating(user, product, rate) =>
      (user, product)
    }
    val predictions =
      model.predict(usersProducts).map { case Rating(user, product, rate) =>
        ((user, product), rate)
      }
    val ratesAndPreds = ratings.map { case Rating(user, product, rate) =>
      ((user, product), rate)
    }.join(predictions)
    val MSE = ratesAndPreds.map { case ((user, product), (r1, r2)) =>
      val err = (r1 - r2)
      err * err
    }.mean()
    println("Mean Squared Error = " + MSE)
结果如下
![](https://github.com/wlwgcdxc/picture/blob/master/ALS0.PNG)

##拿到测试数据，并注册成表，待会儿看看，使用模型给用户做推荐，推荐的商品，实际上用户有没有看
    val data = sc.textFile("/opt/xcdong/data/ALS/test/douban_filter").map(e => e.substring(1, e.length-1)).map(e => e.split(",")).map{ e => Rating(e(0).toInt, e(1).toInt, e(2).toDouble) }.toDF.registerTempTable("testRatings")
    
    def test(user: String, num: Int, table: String) = {
        //使用模型给用户做推荐，num是给用户推荐的商品数目
        val recommend = sc.makeRDD(model.recommendProducts(user.toInt, num))
        //拿到推荐商品的列表
        val recommend_rdd: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = recommend.toDF.select("product").rdd
        //拿到测试数据中，实际这个用户还购买的商品列表
        val real_rdd = sqlContext.sql(String.format("select product from %s where user = %s", table, user)).rdd
        //两个列表做交集，获取模拟的推荐成功的商品列表
        val result = recommend_rdd.intersection(real_rdd)
        result.collect
    }

![](https://github.com/wlwgcdxc/picture/blob/master/ALS1.PNG)
![](https://github.com/wlwgcdxc/picture/blob/master/ALS2.PNG)
![](https://github.com/wlwgcdxc/picture/blob/master/ALS3.PNG)
![](https://github.com/wlwgcdxc/picture/blob/master/ALS4.PNG)
![](https://github.com/wlwgcdxc/picture/blob/master/ALS5.PNG)
##结论
        推荐还是有一定效果的，比如最下边的case，从7万多个图书中，推荐400，就有一个是这个用户之后，实际读过的。
        还有些推荐的图书，效果不太好。可能也是数据量小导致的。这种应该放在线上去测，可能更准确些
