#####先将数据处理下，这个case主要是想用spark提供的ASL，做推荐。
#####ASL需要用户的产品的ID都为数值型，所以先把不是数值型的数据过滤掉
    import org.apache.spark.mllib.recommendation.ALS
    import org.apache.spark.mllib.recommendation.MatrixFactorizationModel
    import org.apache.spark.mllib.recommendation.Rating
    
    // Load and parse the data
    val data = sc.textFile("/opt/xcdong/data/ALS/douban.dat")
    val ratings_1 = data.map(e => e.split("::")).map(e => (e(0), e(1), e(2)) )
    val ratings_2 = ratings_1.filter{ e => (e._1.toString.matches("[0-9]*") == true)}
    ratings_2.repartition(1).saveAsTextFile("/opt/xcdong/data/ALS/douban_filter.dat")

#####这里观察下，数据集中的用户有多少，商品有多少
    // Load and parse the data
    val data = sc.textFile("/opt/xcdong/data/ALS/douban_filter.dat")
    val ratings = data.map(e => e.substring(1, e.length-1)).map(e => e.split(",")).map{ e => Rating(e(0).toInt, e(1).toInt, e(2).toDouble) }
    val ratings_DF = ratings.toDF
    val user_coun = ratings_DF.select("user").distinct().count
    val product_coun = ratings_DF.select("product").distinct().count
    
        user_coun: Long = 251053 
        product_coun: Long = 76377
可以看到用户有25万，商品有7万多

#####将数据分成训练数据和测试数据
    // Load and parse the data
    val data = sc.textFile("/opt/xcdong/data/ALS/douban_filter.dat")
    val ratings_tmp = data.randomSplit(Array(0.6,0.4),seed = 11L)
    ratings_tmp(0).saveAsTextFile("/opt/xcdong/data/ALS/train/douban_filter")
    ratings_tmp(1).saveAsTextFile("/opt/xcdong/data/ALS/test/douban_filter")

######获取测试数据
    // Load and parse the data
    val data = sc.textFile("/opt/xcdong/data/ALS/train/douban_filter")
    val ratings = data.map(e => e.substring(1, e.length-1)).map(e => e.split(",")).map{ e => Rating(e(0).toInt, e(1).toInt, e(2).toDouble) }

#####使用ALS训练模型
    // Build the recommendation model using ALS
    val rank = 10
    val numIterations = 20
    val model = ALS.train(ratings, rank, numIterations, 0.01)

#####在训练集上评估模型，结果肯定比较好
    // Evaluate the model on rating data
    val usersProducts = ratings.map { case Rating(user, product, rate) =>
      (user, product)
    }
    val predictions =
      model.predict(usersProducts).map { case Rating(user, product, rate) =>
        ((user, product), rate)
      }
    val ratesAndPreds = ratings.map { case Rating(user, product, rate) =>
      ((user, product), rate)
    }.join(predictions)
    val MSE = ratesAndPreds.map { case ((user, product), (r1, r2)) =>
      val err = (r1 - r2)
      err * err
    }.mean()
    println("Mean Squared Error = " + MSE)
结果如下
![](https://github.com/wlwgcdxc/picture/blob/master/ALS0.PNG)

###拿到测试数据，并注册成表，待会儿看看，使用模型给用户做推荐，推荐的商品，实际上用户有没有看
    val data = sc.textFile("/opt/xcdong/data/ALS/test/douban_filter").map(e => e.substring(1, e.length-1)).map(e => e.split(",")).map{ e => Rating(e(0).toInt, e(1).toInt, e(2).toDouble) }.toDF.registerTempTable("testRatings")
    
    def test(user: String, num: Int, table: String) = {
        //使用模型给用户做推荐，num是给用户推荐的商品数目
        val recommend = sc.makeRDD(model.recommendProducts(user.toInt, num))
        //拿到推荐商品的列表
        val recommend_rdd: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = recommend.toDF.select("product").rdd
        //拿到测试数据中，实际这个用户还购买的商品列表
        val real_rdd = sqlContext.sql(String.format("select product from %s where user = %s", table, user)).rdd
        //两个列表做交集，获取模拟的推荐成功的商品列表
        val result = recommend_rdd.intersection(real_rdd)
        result.collect
    }

    test("2595309", 20000, "testRatings")
![](https://github.com/wlwgcdxc/picture/blob/master/ALS1.PNG)
    test("8590089", 3000, "testRatings")
![](https://github.com/wlwgcdxc/picture/blob/master/ALS2.PNG)
    test("39167140", 1800, "testRatings")
![](https://github.com/wlwgcdxc/picture/blob/master/ALS3.PNG)
    test("3272114", 800, "testRatings")
![](https://github.com/wlwgcdxc/picture/blob/master/ALS4.PNG)
    test("4217197", 400, "testRatings")
![](https://github.com/wlwgcdxc/picture/blob/master/ALS5.PNG)
